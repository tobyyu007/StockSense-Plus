{"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Train llama3 with LoRA\n[Source of this notebook](https://www.philschmid.de/fsdp-qlora-llama3#3-fine-tune-the-llm-with-pytorch-fsdp-q-lora-and-sdpa)\n\nThis notebook is designed for Kaggle notebook with 2 Nvidia T4 GPUs","metadata":{}},{"cell_type":"markdown","source":"### Enviornment setup\n- Set your `HF_TOKEN` at `Add-ons -> Secrets`","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nHF_TOKEN = user_secrets.get_secret(\"HF_TOKEN\")\n# HF_TOKEN_WRITE = user_secrets.get_secret(\"HF_TOKEN_WRITE\")\n# HF_TOKEN_WRITE = user_secrets.get_secret(\"HF_TOKEN_WRITE\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-05-09T02:01:02.782144Z","iopub.execute_input":"2024-05-09T02:01:02.782996Z","iopub.status.idle":"2024-05-09T02:01:02.970108Z","shell.execute_reply.started":"2024-05-09T02:01:02.782960Z","shell.execute_reply":"2024-05-09T02:01:02.969063Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Install Pytorch for FSDP and FA/SDPA\n%pip install \"torch==2.2.2\" tensorboard\n \n# Install Hugging Face libraries\n%pip install  --upgrade \"transformers==4.40.0\" \"datasets==2.18.0\" \"accelerate==0.29.3\" \"evaluate==0.4.1\" \"bitsandbytes==0.43.1\" \"huggingface_hub==0.22.2\" \"trl==0.8.6\" \"peft==0.10.0\"","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-09T02:01:02.972177Z","iopub.execute_input":"2024-05-09T02:01:02.972597Z","iopub.status.idle":"2024-05-09T02:03:45.337533Z","shell.execute_reply.started":"2024-05-09T02:01:02.972566Z","shell.execute_reply":"2024-05-09T02:03:45.336417Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mCollecting torch==2.2.2\n  Using cached torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\nRequirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2) (3.13.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.2) (2024.2.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.2)\n  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.2)\n  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.2)\n  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.2)\n  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.2)\n  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.2)\n  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.2)\n  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.2)\n  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.2)\n  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.2)\n  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.2)\n  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.2)\n  Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.2)\n  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\nRequirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.51.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.26.4)\nRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (2.31.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\nRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.2) (1.3.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\nDownloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n  Attempting uninstall: torch\n    Found existing installation: torch 2.1.2\n    Uninstalling torch-2.1.2:\n      Successfully uninstalled torch-2.1.2\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 triton-2.2.0\nNote: you may need to restart the kernel to use updated packages.\n\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mCollecting transformers==4.40.0\n  Using cached transformers-4.40.0-py3-none-any.whl.metadata (137 kB)\nRequirement already satisfied: datasets==2.18.0 in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: accelerate==0.29.3 in /opt/conda/lib/python3.10/site-packages (0.29.3)\nCollecting evaluate==0.4.1\n  Using cached evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: bitsandbytes==0.43.1 in /opt/conda/lib/python3.10/site-packages (0.43.1)\nRequirement already satisfied: huggingface_hub==0.22.2 in /opt/conda/lib/python3.10/site-packages (0.22.2)\nCollecting trl==0.8.6\n  Using cached trl-0.8.6-py3-none-any.whl.metadata (11 kB)\nCollecting peft==0.10.0\n  Using cached peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (2.31.0)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0) (4.66.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (2.1.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (3.9.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.29.3) (2.2.2)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.1) (0.18.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub==0.22.2) (4.9.0)\nRequirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.6) (0.8.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.40.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0) (2024.2.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (3.1.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (8.9.2.26)\nRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.3.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (11.0.2.54)\nRequirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (10.3.2.106)\nRequirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (11.4.5.107)\nRequirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.0.106)\nRequirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (2.19.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (12.1.105)\nRequirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.29.3) (2.2.0)\nRequirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.29.3) (12.4.127)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (13.7.0)\nRequirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.6) (1.7.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (2.17.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.29.3) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.29.3) (1.3.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.6) (0.1.2)\nUsing cached transformers-4.40.0-py3-none-any.whl (9.0 MB)\nUsing cached evaluate-0.4.1-py3-none-any.whl (84 kB)\nUsing cached trl-0.8.6-py3-none-any.whl (245 kB)\nUsing cached peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[33mWARNING: Ignoring invalid distribution -ransformers (/opt/conda/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: transformers, trl, peft, evaluate\nSuccessfully installed evaluate-0.4.1 peft-0.10.0 transformers-4.40.0 trl-0.8.6\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"!huggingface-cli login --token $HF_TOKEN","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:03:45.339040Z","iopub.execute_input":"2024-05-09T02:03:45.339391Z","iopub.status.idle":"2024-05-09T02:03:46.945026Z","shell.execute_reply.started":"2024-05-09T02:03:45.339359Z","shell.execute_reply":"2024-05-09T02:03:46.943879Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load and prepare the dataset","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset, DatasetDict\n \n# Convert dataset to OAI messages\nsystem_message = \"\"\"You are a seasoned stock market analyst. What is the summary of this financial text\"\"\"\n\ndef create_conversation(sample):\n#     return {\n#         \"messages\": [\n#             {\"role\": \"system\", \"content\": system_message},\n#             {\"role\": \"user\", \"content\": sample[\"document\"]},\n#             {\"role\": \"assistant\", \"content\": sample[\"summary\"]}\n#         ]\n#     }\n    return {\n        \"messages\": [\n            {\"role\": \"system\", \"content\": sample[\"Instruction\"]},\n            {\"role\": \"user\", \"content\": sample[\"Input\"]},\n            {\"role\": \"assistant\", \"content\": sample[\"Output\"]}\n        ]\n    }\n \n# Load dataset from the hub\ndataset = load_dataset(\"tobyyu007/Stocksense-Prediction-Current-Week\", split=\"train\")\n# print(dataset)\n# dataset = dataset.select(range(0, 323))\n \n# Convert dataset to OAI messages\ndataset = dataset.map(create_conversation, remove_columns=dataset.features, batched=False)\n# split dataset into 10,000 training samples and 2,500 test samples\ndataset = dataset.train_test_split(test_size=30, seed=42)\n\nprint(dataset[\"train\"][123][\"messages\"])\n\n# save datasets to disk\ndataset[\"train\"].to_json(\"train_dataset.json\", orient=\"records\", force_ascii=False)\ndataset[\"test\"].to_json(\"test_dataset.json\", orient=\"records\", force_ascii=False)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-09T02:03:46.946807Z","iopub.execute_input":"2024-05-09T02:03:46.947673Z","iopub.status.idle":"2024-05-09T02:03:51.344619Z","shell.execute_reply.started":"2024-05-09T02:03:46.947633Z","shell.execute_reply":"2024-05-09T02:03:51.343727Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading data: 100%|██████████| 287k/287k [00:00<00:00, 2.33MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"674b45939360416eb342b6a89c0f92ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/321 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c547a9cee354a3f97c8d1978aae539e"}},"metadata":{}},{"name":"stdout","text":"[{'content': \"You are a seasoned stock market analyst. Your task is to predict the companies' stock price movement next week based on this week's positive headlines and negative headlines. Give me answer in this format {increase/decrease} in {percentange} or flat.\", 'role': 'system'}, {'content': \"Company news during this period are listed below:\\n\\nPositive Headlines:\\n* Verify your identity to ensure smooth Apple Pay Cash transactions\\n* Apple wins EU trademark case against Xiaomi\\n* Why the 'gay wedding cake' Supreme Court case is really about corporate governance\\n* As fans await update for 3-year-old Mac mini, Apple classifies mid-2011 models 'obsolete'\\n* Coinbase was number one on Apple's app store after bitcoin’s wild surge\\n\\nNegative Headlines:\\n* Apple's app of the year battles the anxiety that smartphones give us\\n* Study finds you tend to break your old iPhone when a new one comes out\\n* The One Glaring Problem With Apple Stock (NASDAQ:AAPL)\\n* Apple Pay Cash leverages Discover Network for new virtual debit card\\n* Forget Amazon and Alphabet: Here's Why Apple Will Become the \\n\\n\", 'role': 'user'}, {'content': 'increased in 0.75%', 'role': 'assistant'}]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"716ee1d9814d424f81c9ac86f88d0dc3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db1d17089cbd433da18817f5260a249f"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"28952"},"metadata":{}}]},{"cell_type":"markdown","source":"### Load base model and setup training parameters","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load jsonl data from disk\ndataset = load_dataset(\"json\", data_files=\"train_dataset.json\", split=\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:03:51.348010Z","iopub.execute_input":"2024-05-09T02:03:51.348643Z","iopub.status.idle":"2024-05-09T02:03:51.683572Z","shell.execute_reply.started":"2024-05-09T02:03:51.348607Z","shell.execute_reply":"2024-05-09T02:03:51.682705Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac03c465389c4434b3816ac488c2e15b"}},"metadata":{}}]},{"cell_type":"code","source":"%%writefile llama_3_8b_fsdp_qlora.yaml\n# script parameters\nmodel_id: \"meta-llama/Meta-Llama-3-8B-Instruct\" # Hugging Face model id\ndataset_path: \".\"                      # path to dataset\nmax_seq_len:  3072 # 2048              # max sequence length for model and packing of the dataset\n# training parameters\noutput_dir: \"/home/jupyter/llama-3-8b-FinGPT\" # Temporary output directory for model checkpoints\nreport_to: \"tensorboard\"               # report metrics to tensorboard\nlearning_rate: 0.0005                  # learning rate 2e-4\nlr_scheduler_type: \"constant\"          # learning rate scheduler\nnum_train_epochs: 4                    # number of training epochs\nper_device_train_batch_size: 1         # batch size per device during training\nper_device_eval_batch_size: 1          # batch size for evaluation\ngradient_accumulation_steps: 2         # number of steps before performing a backward/update pass\noptim: adamw_torch                     # use torch adamw optimizer\nlogging_steps: 10                      # log every 10 steps\nsave_strategy: epoch                   # save checkpoint every epoch\nevaluation_strategy: epoch             # evaluate every epoch\nmax_grad_norm: 0.3                     # max gradient norm\nwarmup_ratio: 0.03                     # warmup ratio\nbf16: false                             # use bfloat16 precision\ntf32: false                             # use tf32 precision\ngradient_checkpointing: true           # use gradient checkpointing to save memory\nhub_private_repo: true\n# FSDP parameters: https://huggingface.co/docs/transformers/main/en/fsdp\nfsdp: \"full_shard auto_wrap\" # remove offload if enough GPU memory\nfsdp_config:\n  backward_prefetch: \"backward_pre\"\n  forward_prefetch: \"false\"\n  use_orig_params: \"false\"","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:03:51.684690Z","iopub.execute_input":"2024-05-09T02:03:51.684961Z","iopub.status.idle":"2024-05-09T02:03:51.691827Z","shell.execute_reply.started":"2024-05-09T02:03:51.684935Z","shell.execute_reply":"2024-05-09T02:03:51.690985Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Writing llama_3_8b_fsdp_qlora.yaml\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile run_fsdp_qlora.py\nimport logging\nfrom dataclasses import dataclass, field\nimport os\nimport random\nimport torch\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, TrainingArguments\nfrom trl.commands.cli_utils import  TrlParser\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n        set_seed,\n\n)\nfrom trl import setup_chat_format\nfrom peft import LoraConfig\n\n\nfrom trl import (\n   SFTTrainer)\n\n# Comment in if you want to use the Llama 3 instruct template but make sure to add modules_to_save\n# LLAMA_3_CHAT_TEMPLATE=\"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"\n\n# Anthropic/Vicuna like template without the need for special tokens\nLLAMA_3_CHAT_TEMPLATE = (\n    \"{% for message in messages %}\"\n        \"{% if message['role'] == 'system' %}\"\n            \"{{ message['content'] }}\"\n        \"{% elif message['role'] == 'user' %}\"\n            \"{{ '\\n\\nHuman: ' + message['content'] +  eos_token }}\"\n        \"{% elif message['role'] == 'assistant' %}\"\n            \"{{ '\\n\\nAssistant: '  + message['content'] +  eos_token  }}\"\n        \"{% endif %}\"\n    \"{% endfor %}\"\n    \"{% if add_generation_prompt %}\"\n    \"{{ '\\n\\nAssistant: ' }}\"\n    \"{% endif %}\"\n)\n\n\n# ACCELERATE_USE_FSDP=1 FSDP_CPU_RAM_EFFICIENT_LOADING=1 torchrun --nproc_per_node=4 ./scripts/run_fsdp_qlora.py --config llama_3_70b_fsdp_qlora.yaml\n\n@dataclass\nclass ScriptArguments:\n    dataset_path: str = field(\n        default=None,\n        metadata={\n            \"help\": \"Path to the dataset\"\n        },\n    )\n    model_id: str = field(\n        default=None, metadata={\"help\": \"Model ID to use for SFT training\"}\n    )\n    max_seq_length: int = field(\n        default=512, metadata={\"help\": \"The maximum sequence length for SFT Trainer\"}\n    )\n\n\ndef training_function(script_args, training_args):\n    ################\n    # Dataset\n    ################\n    \n    train_dataset = load_dataset(\n        \"json\",\n        data_files=os.path.join(script_args.dataset_path, \"train_dataset.json\"),\n        split=\"train\",\n    )\n    test_dataset = load_dataset(\n        \"json\",\n        data_files=os.path.join(script_args.dataset_path, \"test_dataset.json\"),\n        split=\"train\",\n    )\n\n    ################\n    # Model & Tokenizer\n    ################\n\n    # Tokenizer        \n    tokenizer = AutoTokenizer.from_pretrained(script_args.model_id, use_fast=True)\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE\n    \n    # template dataset\n    def template_dataset(examples):\n        return{\"text\":  tokenizer.apply_chat_template(examples[\"messages\"], tokenize=False)}\n    \n    train_dataset = train_dataset.map(template_dataset, remove_columns=[\"messages\"])\n    test_dataset = test_dataset.map(template_dataset, remove_columns=[\"messages\"])\n    \n    # print random sample\n    with training_args.main_process_first(\n        desc=\"Log a few random samples from the processed training set\"\n    ):\n        for index in random.sample(range(len(train_dataset)), 2):\n            print(train_dataset[index][\"text\"])\n\n    # Model    \n    torch_dtype = torch.bfloat16\n    quant_storage_dtype = torch.bfloat16\n\n    quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_use_double_quant=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch_dtype,\n            bnb_4bit_quant_storage=quant_storage_dtype,\n        )\n\n    model = AutoModelForCausalLM.from_pretrained(\n        script_args.model_id,\n        quantization_config=quantization_config,\n        attn_implementation=\"sdpa\", # use sdpa, alternatively use \"flash_attention_2\"\n        torch_dtype=quant_storage_dtype,\n        use_cache=False if training_args.gradient_checkpointing else True,  # this is needed for gradient checkpointing\n    )\n    \n    if training_args.gradient_checkpointing:\n        model.gradient_checkpointing_enable()\n\n    ################\n    # PEFT\n    ################\n\n    # LoRA config based on QLoRA paper & Sebastian Raschka experiment\n    peft_config = LoraConfig(\n        lora_alpha=8,\n        lora_dropout=0.05,\n        r=16,\n        bias=\"none\",\n        target_modules=\"all-linear\",\n        task_type=\"CAUSAL_LM\",\n#         modules_to_save = [\"lm_head\", \"embed_tokens\"] # add if you want to use the Llama 3 instruct template\n    )\n\n    ################\n    # Training\n    ################\n    trainer = SFTTrainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        dataset_text_field=\"text\",\n        eval_dataset=test_dataset,\n        peft_config=peft_config,\n        max_seq_length=script_args.max_seq_length,\n        tokenizer=tokenizer,\n        packing=True,\n        dataset_kwargs={\n            \"add_special_tokens\": False,  # We template with special tokens\n            \"append_concat_token\": False,  # No need to add additional separator token\n        },\n    )\n    if trainer.accelerator.is_main_process:\n        trainer.model.print_trainable_parameters()\n\n    ##########################\n    # Train model\n    ##########################\n    checkpoint = None\n    if training_args.resume_from_checkpoint is not None:\n        checkpoint = training_args.resume_from_checkpoint\n    trainer.train(resume_from_checkpoint=checkpoint)\n\n    ##########################\n    # SAVE MODEL FOR SAGEMAKER\n    ##########################\n    if trainer.is_fsdp_enabled:\n        trainer.accelerator.state.fsdp_plugin.set_state_dict_type(\"FULL_STATE_DICT\")\n    trainer.save_model()\n    \nif __name__ == \"__main__\":\n    parser = TrlParser((ScriptArguments, TrainingArguments))\n    script_args, training_args = parser.parse_args_and_config()    \n    \n    # set use reentrant to False\n    if training_args.gradient_checkpointing:\n        training_args.gradient_checkpointing_kwargs = {\"use_reentrant\": True}\n    # set seed\n    set_seed(training_args.seed)\n  \n    # launch training\n    training_function(script_args, training_args)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:03:51.693140Z","iopub.execute_input":"2024-05-09T02:03:51.693429Z","iopub.status.idle":"2024-05-09T02:03:51.710964Z","shell.execute_reply.started":"2024-05-09T02:03:51.693399Z","shell.execute_reply":"2024-05-09T02:03:51.710103Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Writing run_fsdp_qlora.py\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Train Model","metadata":{}},{"cell_type":"markdown","source":"##### Release unreferenced memory in Python","metadata":{}},{"cell_type":"code","source":"import gc\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:03:51.712024Z","iopub.execute_input":"2024-05-09T02:03:51.712377Z","iopub.status.idle":"2024-05-09T02:03:51.792882Z","shell.execute_reply.started":"2024-05-09T02:03:51.712345Z","shell.execute_reply":"2024-05-09T02:03:51.791925Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"133"},"metadata":{}}]},{"cell_type":"markdown","source":"##### Start training with torchrun","metadata":{}},{"cell_type":"code","source":"!ACCELERATE_USE_FSDP=1 FSDP_CPU_RAM_EFFICIENT_LOADING=1 torchrun --nproc_per_node=2 ./run_fsdp_qlora.py --config llama_3_8b_fsdp_qlora.yaml","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-09T02:03:51.794031Z","iopub.execute_input":"2024-05-09T02:03:51.794397Z","iopub.status.idle":"2024-05-09T02:58:53.330457Z","shell.execute_reply.started":"2024-05-09T02:03:51.794373Z","shell.execute_reply":"2024-05-09T02:58:53.329395Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"[2024-05-09 02:03:54,639] torch.distributed.run: [WARNING] \n[2024-05-09 02:03:54,639] torch.distributed.run: [WARNING] *****************************************\n[2024-05-09 02:03:54,639] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n[2024-05-09 02:03:54,639] torch.distributed.run: [WARNING] *****************************************\n2024-05-09 02:04:03.944536: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-09 02:04:03.944536: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-09 02:04:03.944604: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-09 02:04:03.944661: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-09 02:04:04.114833: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2024-05-09 02:04:04.114825: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nGenerating train split: 291 examples [00:00, 51685.05 examples/s]\nGenerating train split: 30 examples [00:00, 17015.43 examples/s]\ntokenizer_config.json: 100%|████████████████| 51.0k/51.0k [00:00<00:00, 820kB/s]\ntokenizer.json: 100%|██████████████████████| 9.09M/9.09M [00:00<00:00, 22.8MB/s]\nspecial_tokens_map.json: 100%|████████████████| 73.0/73.0 [00:00<00:00, 454kB/s]\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nMap: 100%|███████████████████████████| 291/291 [00:00<00:00, 3807.52 examples/s]\nMap: 100%|█████████████████████████████| 30/30 [00:00<00:00, 3809.31 examples/s]\nMap: 100%|████████████████████████████| 291/291 [00:00<00:00, 820.01 examples/s]\nYou are a seasoned stock market analyst. Your task is to predict the companies' stock price movement next week based on this week's positive headlines and negative headlines. Give me answer in this format {increase/decrease} in {percentange} or flat.\n\nHuman: Company news during this period are listed below:\n\nPositive Headlines:\n* Apple’s share buyback is a smarter use of its cash than these 4 other options\n* Berkshire Hathaway and Apple Are a Perfect Match\n* Ask the Experts: The Ideal Vega for Options Traders\n* Tesla Is About to Give a Bunch of Folks a Free Upgrade … Again\n* iPad saves construction firm $1.8 million annually\n\nNegative Headlines:\n* 3 Overvalued Stocks That May Fall Sharply\n* Apple abandons its plan to build $1bn data center in western Ireland \n\n<|end_of_text|>\n\nAssistant: decreased in -0.98%<|end_of_text|>\nYou are a seasoned stock market analyst. Your task is to predict the companies' stock price movement next week based on this week's positive headlines and negative headlines. Give me answer in this format {increase/decrease} in {percentange} or flat.\n\nHuman: Company news during this period are listed below:\n\nPositive Headlines:\n* Apple's best-paid female employee earns nearly twice as much as CEO Tim Cook (AAPL)\n* Report: Broader iPhone lineup creates more stability for AAPL\n* Kim Kardashian gifted Apple, Netflix, Amazon stocks\n* Stocks seek rebound in final trading days of 2017\n* Chicago flagship Apple Retail store roof not well suited for snow, ice\n\nNegative Headlines:\n* Apple battled a fashion brand called “Steve Jobs”—and lost\n* Apple's Planned Obsolescence Strategy (NASDAQ:AAPL)\n* Apple's $213 Billion Problem (NASDAQ:AAPL)\n* Apple faces lawsuits after saying it slows down aging iPhones\n* How your next navigation app could reduce your chances of a car crash\n\n<|end_of_text|>\n\nAssistant: increased in 1.59%<|end_of_text|>\nYou are a seasoned stock market analyst. Your task is to predict the companies' stock price movement next week based on this week's positive headlines and negative headlines. Give me answer in this format {increase/decrease} in {percentange} or flat.\n\nHuman: Company news during this period are listed below:\n\nPositive Headlines:\n* Apple’s share buyback is a smarter use of its cash than these 4 other options\n* Berkshire Hathaway and Apple Are a Perfect Match\n* Ask the Experts: The Ideal Vega for Options Traders\n* Tesla Is About to Give a Bunch of Folks a Free Upgrade … Again\n* iPad saves construction firm $1.8 million annually\n\nNegative Headlines:\n* 3 Overvalued Stocks That May Fall Sharply\n* Apple abandons its plan to build $1bn data center in western Ireland \n\n<|end_of_text|>\n\nAssistant: decreased in -0.98%<|end_of_text|>\nYou are a seasoned stock market analyst. Your task is to predict the companies' stock price movement next week based on this week's positive headlines and negative headlines. Give me answer in this format {increase/decrease} in {percentange} or flat.\n\nHuman: Company news during this period are listed below:\n\nPositive Headlines:\n* Apple's best-paid female employee earns nearly twice as much as CEO Tim Cook (AAPL)\n* Report: Broader iPhone lineup creates more stability for AAPL\n* Kim Kardashian gifted Apple, Netflix, Amazon stocks\n* Stocks seek rebound in final trading days of 2017\n* Chicago flagship Apple Retail store roof not well suited for snow, ice\n\nNegative Headlines:\n* Apple battled a fashion brand called “Steve Jobs”—and lost\n* Apple's Planned Obsolescence Strategy (NASDAQ:AAPL)\n* Apple's $213 Billion Problem (NASDAQ:AAPL)\n* Apple faces lawsuits after saying it slows down aging iPhones\n* How your next navigation app could reduce your chances of a car crash\n\n<|end_of_text|>\n\nAssistant: increased in 1.59%<|end_of_text|>\nconfig.json: 100%|█████████████████████████████| 654/654 [00:00<00:00, 3.11MB/s]\nmodel.safetensors.index.json: 100%|████████| 23.9k/23.9k [00:00<00:00, 71.0MB/s]\nDownloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]\nmodel-00001-of-00004.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\nmodel-00001-of-00004.safetensors:   0%|     | 21.0M/4.98G [00:00<00:28, 176MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   1%|     | 52.4M/4.98G [00:00<00:20, 240MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   2%|     | 83.9M/4.98G [00:00<00:18, 262MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   2%|▏     | 115M/4.98G [00:00<00:17, 272MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   3%|▏     | 147M/4.98G [00:00<00:17, 278MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   4%|▏     | 178M/4.98G [00:00<00:16, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   4%|▎     | 210M/4.98G [00:00<00:16, 287MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   5%|▎     | 241M/4.98G [00:00<00:16, 290MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   5%|▎     | 273M/4.98G [00:00<00:16, 292MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   6%|▎     | 304M/4.98G [00:01<00:15, 293MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   7%|▍     | 336M/4.98G [00:01<00:15, 294MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   7%|▍     | 367M/4.98G [00:01<00:15, 295MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   8%|▍     | 398M/4.98G [00:01<00:15, 295MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   9%|▌     | 430M/4.98G [00:01<00:15, 293MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:   9%|▌     | 461M/4.98G [00:01<00:15, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  10%|▌     | 493M/4.98G [00:01<00:15, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  11%|▋     | 524M/4.98G [00:01<00:15, 290MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  11%|▋     | 556M/4.98G [00:01<00:15, 290MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  12%|▋     | 587M/4.98G [00:02<00:15, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  12%|▋     | 619M/4.98G [00:02<00:14, 293MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  13%|▊     | 650M/4.98G [00:02<00:14, 294MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  14%|▊     | 682M/4.98G [00:02<00:14, 295MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  14%|▊     | 713M/4.98G [00:02<00:14, 295MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  15%|▉     | 744M/4.98G [00:02<00:14, 294MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  16%|▉     | 776M/4.98G [00:02<00:14, 295MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  16%|▉     | 807M/4.98G [00:02<00:14, 296MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  17%|█     | 839M/4.98G [00:02<00:13, 296MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  17%|█     | 870M/4.98G [00:03<00:13, 296MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  18%|█     | 902M/4.98G [00:03<00:13, 297MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  19%|█▏    | 933M/4.98G [00:03<00:13, 298MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  19%|█▏    | 965M/4.98G [00:03<00:13, 298MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  20%|█▏    | 996M/4.98G [00:03<00:13, 298MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  21%|█    | 1.03G/4.98G [00:03<00:13, 298MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  21%|█    | 1.06G/4.98G [00:03<00:13, 297MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  22%|█    | 1.09G/4.98G [00:03<00:13, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  23%|█▏   | 1.12G/4.98G [00:03<00:13, 285MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  23%|█▏   | 1.15G/4.98G [00:03<00:13, 278MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  24%|█▏   | 1.18G/4.98G [00:04<00:13, 283MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  24%|█▏   | 1.22G/4.98G [00:04<00:13, 286MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  25%|█▎   | 1.25G/4.98G [00:04<00:12, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  26%|█▎   | 1.28G/4.98G [00:04<00:12, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  26%|█▎   | 1.31G/4.98G [00:04<00:12, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  27%|█▎   | 1.34G/4.98G [00:04<00:12, 292MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  28%|█▍   | 1.37G/4.98G [00:04<00:12, 295MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  28%|█▍   | 1.41G/4.98G [00:04<00:12, 295MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  29%|█▍   | 1.44G/4.98G [00:04<00:12, 293MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  29%|█▍   | 1.47G/4.98G [00:05<00:12, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  30%|█▌   | 1.50G/4.98G [00:05<00:12, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  31%|█▌   | 1.53G/4.98G [00:05<00:12, 286MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  31%|█▌   | 1.56G/4.98G [00:05<00:11, 287MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  32%|█▌   | 1.59G/4.98G [00:05<00:11, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  33%|█▋   | 1.63G/4.98G [00:05<00:11, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  33%|█▋   | 1.66G/4.98G [00:05<00:11, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  34%|█▋   | 1.69G/4.98G [00:05<00:11, 286MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  35%|█▋   | 1.72G/4.98G [00:05<00:11, 285MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  35%|█▊   | 1.75G/4.98G [00:06<00:11, 286MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  36%|█▊   | 1.78G/4.98G [00:06<00:11, 286MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  36%|█▊   | 1.81G/4.98G [00:06<00:11, 287MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  37%|█▊   | 1.85G/4.98G [00:06<00:10, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  38%|█▉   | 1.88G/4.98G [00:06<00:10, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  38%|█▉   | 1.91G/4.98G [00:06<00:10, 290MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  39%|█▉   | 1.94G/4.98G [00:06<00:10, 290MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  40%|█▉   | 1.97G/4.98G [00:06<00:10, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  40%|██   | 2.00G/4.98G [00:06<00:10, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  41%|██   | 2.03G/4.98G [00:07<00:10, 290MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  42%|██   | 2.07G/4.98G [00:07<00:10, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  42%|██   | 2.10G/4.98G [00:07<00:09, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  43%|██▏  | 2.13G/4.98G [00:07<00:09, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  43%|██▏  | 2.16G/4.98G [00:07<00:09, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  44%|██▏  | 2.19G/4.98G [00:07<00:09, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  45%|██▏  | 2.22G/4.98G [00:07<00:09, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  45%|██▎  | 2.25G/4.98G [00:07<00:09, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  46%|██▎  | 2.29G/4.98G [00:07<00:09, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  47%|██▎  | 2.32G/4.98G [00:08<00:09, 292MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  47%|██▎  | 2.35G/4.98G [00:08<00:09, 292MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  48%|██▍  | 2.38G/4.98G [00:08<00:08, 292MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  48%|██▍  | 2.41G/4.98G [00:08<00:08, 292MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  49%|██▍  | 2.44G/4.98G [00:08<00:08, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  50%|██▍  | 2.47G/4.98G [00:08<00:08, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  50%|██▌  | 2.51G/4.98G [00:08<00:08, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  51%|██▌  | 2.54G/4.98G [00:08<00:08, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  52%|██▌  | 2.57G/4.98G [00:08<00:08, 287MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  52%|██▌  | 2.60G/4.98G [00:08<00:08, 287MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  53%|██▋  | 2.63G/4.98G [00:09<00:08, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  54%|██▋  | 2.66G/4.98G [00:09<00:08, 287MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  54%|██▋  | 2.69G/4.98G [00:09<00:08, 283MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  55%|██▋  | 2.73G/4.98G [00:09<00:07, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  55%|██▊  | 2.76G/4.98G [00:09<00:07, 283MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  56%|██▊  | 2.79G/4.98G [00:09<00:07, 283MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  57%|██▊  | 2.82G/4.98G [00:09<00:07, 278MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  57%|██▊  | 2.85G/4.98G [00:09<00:07, 280MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  58%|██▉  | 2.88G/4.98G [00:09<00:07, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  59%|██▉  | 2.92G/4.98G [00:10<00:07, 283MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  59%|██▉  | 2.95G/4.98G [00:10<00:07, 283MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  60%|██▉  | 2.98G/4.98G [00:10<00:07, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  60%|███  | 3.01G/4.98G [00:10<00:06, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  61%|███  | 3.04G/4.98G [00:10<00:06, 283MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  62%|███  | 3.07G/4.98G [00:10<00:06, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  62%|███  | 3.10G/4.98G [00:10<00:06, 287MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  63%|███▏ | 3.14G/4.98G [00:10<00:06, 290MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  64%|███▏ | 3.17G/4.98G [00:10<00:06, 294MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  64%|███▏ | 3.20G/4.98G [00:11<00:06, 294MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  65%|███▏ | 3.23G/4.98G [00:11<00:05, 295MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  66%|███▎ | 3.26G/4.98G [00:11<00:05, 292MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  66%|███▎ | 3.29G/4.98G [00:11<00:05, 288MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  67%|███▎ | 3.32G/4.98G [00:11<00:05, 289MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  67%|███▎ | 3.36G/4.98G [00:11<00:05, 291MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  68%|███▍ | 3.39G/4.98G [00:11<00:05, 290MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  69%|███▍ | 3.42G/4.98G [00:11<00:05, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  69%|███▍ | 3.45G/4.98G [00:11<00:05, 286MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  70%|███▍ | 3.48G/4.98G [00:12<00:05, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  71%|███▌ | 3.51G/4.98G [00:12<00:05, 279MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  71%|███▌ | 3.54G/4.98G [00:12<00:05, 277MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  72%|███▌ | 3.58G/4.98G [00:12<00:05, 277MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  72%|███▌ | 3.61G/4.98G [00:12<00:05, 274MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  73%|███▋ | 3.64G/4.98G [00:12<00:04, 275MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  74%|███▋ | 3.67G/4.98G [00:12<00:04, 278MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  74%|███▋ | 3.70G/4.98G [00:12<00:04, 275MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  75%|███▊ | 3.73G/4.98G [00:12<00:04, 274MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  76%|███▊ | 3.76G/4.98G [00:13<00:04, 273MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  76%|███▊ | 3.80G/4.98G [00:13<00:06, 176MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  77%|███▊ | 3.83G/4.98G [00:13<00:05, 193MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  78%|███▉ | 3.86G/4.98G [00:13<00:05, 201MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  78%|███▉ | 3.89G/4.98G [00:13<00:05, 215MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  79%|███▉ | 3.92G/4.98G [00:13<00:04, 228MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  79%|███▉ | 3.95G/4.98G [00:14<00:04, 236MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  80%|████ | 3.98G/4.98G [00:14<00:04, 242MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  81%|████ | 4.02G/4.98G [00:14<00:03, 241MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  81%|████ | 4.05G/4.98G [00:14<00:03, 245MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  82%|████ | 4.08G/4.98G [00:14<00:03, 247MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  83%|████▏| 4.11G/4.98G [00:14<00:03, 254MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  83%|████▏| 4.14G/4.98G [00:14<00:03, 260MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  84%|████▏| 4.17G/4.98G [00:14<00:03, 263MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  84%|████▏| 4.20G/4.98G [00:15<00:02, 266MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  85%|████▎| 4.24G/4.98G [00:15<00:02, 270MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  86%|████▎| 4.27G/4.98G [00:15<00:02, 273MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  86%|████▎| 4.30G/4.98G [00:15<00:02, 274MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  87%|████▎| 4.33G/4.98G [00:15<00:02, 276MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  88%|████▍| 4.36G/4.98G [00:15<00:02, 279MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  88%|████▍| 4.39G/4.98G [00:15<00:02, 282MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  89%|████▍| 4.42G/4.98G [00:15<00:01, 283MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  90%|████▍| 4.46G/4.98G [00:15<00:01, 280MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  90%|████▌| 4.49G/4.98G [00:16<00:01, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  91%|████▌| 4.52G/4.98G [00:16<00:01, 284MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  91%|████▌| 4.55G/4.98G [00:16<00:01, 282MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  92%|████▌| 4.58G/4.98G [00:16<00:01, 280MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  93%|████▋| 4.61G/4.98G [00:16<00:01, 280MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  93%|████▋| 4.65G/4.98G [00:16<00:01, 280MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  94%|████▋| 4.68G/4.98G [00:16<00:01, 281MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  95%|████▋| 4.71G/4.98G [00:16<00:00, 279MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  95%|████▊| 4.74G/4.98G [00:16<00:00, 280MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  96%|████▊| 4.77G/4.98G [00:17<00:00, 281MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  96%|████▊| 4.80G/4.98G [00:17<00:00, 280MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  97%|████▊| 4.83G/4.98G [00:17<00:00, 278MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  98%|████▉| 4.87G/4.98G [00:17<00:00, 276MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  98%|████▉| 4.90G/4.98G [00:17<00:00, 277MB/s]\u001b[A\nmodel-00001-of-00004.safetensors:  99%|████▉| 4.93G/4.98G [00:17<00:00, 280MB/s]\u001b[A\nmodel-00001-of-00004.safetensors: 100%|█████| 4.98G/4.98G [00:17<00:00, 280MB/s]\u001b[A\nDownloading shards:  25%|██████▎                  | 1/4 [00:17<00:53, 17.93s/it]\nmodel-00002-of-00004.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\nmodel-00002-of-00004.safetensors:   1%|     | 31.5M/5.00G [00:00<00:16, 297MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   1%|     | 62.9M/5.00G [00:00<00:17, 287MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   2%|     | 94.4M/5.00G [00:00<00:17, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   3%|▏     | 126M/5.00G [00:00<00:17, 280MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   3%|▏     | 157M/5.00G [00:00<00:17, 280MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   4%|▏     | 189M/5.00G [00:00<00:17, 281MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   4%|▎     | 220M/5.00G [00:00<00:17, 280MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   5%|▎     | 252M/5.00G [00:00<00:16, 281MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   6%|▎     | 283M/5.00G [00:01<00:16, 282MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   6%|▍     | 315M/5.00G [00:01<00:16, 281MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   7%|▍     | 346M/5.00G [00:01<00:16, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   8%|▍     | 377M/5.00G [00:01<00:16, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   8%|▍     | 409M/5.00G [00:01<00:16, 284MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   9%|▌     | 440M/5.00G [00:01<00:16, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:   9%|▌     | 472M/5.00G [00:01<00:15, 289MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  10%|▌     | 503M/5.00G [00:01<00:15, 288MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  11%|▋     | 535M/5.00G [00:01<00:15, 290MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  11%|▋     | 566M/5.00G [00:01<00:15, 292MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  12%|▋     | 598M/5.00G [00:02<00:14, 294MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  13%|▊     | 629M/5.00G [00:02<00:14, 294MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  13%|▊     | 661M/5.00G [00:02<00:14, 294MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  14%|▊     | 692M/5.00G [00:02<00:14, 290MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  14%|▊     | 724M/5.00G [00:02<00:14, 288MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  15%|▉     | 755M/5.00G [00:02<00:14, 287MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  16%|▉     | 786M/5.00G [00:02<00:14, 288MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  16%|▉     | 818M/5.00G [00:02<00:14, 288MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  17%|█     | 849M/5.00G [00:02<00:14, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  18%|█     | 881M/5.00G [00:03<00:14, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  18%|█     | 912M/5.00G [00:03<00:14, 280MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  19%|█▏    | 944M/5.00G [00:03<00:14, 279MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  20%|█▏    | 975M/5.00G [00:03<00:14, 279MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  20%|█    | 1.01G/5.00G [00:03<00:14, 277MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  21%|█    | 1.04G/5.00G [00:03<00:14, 278MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  21%|█    | 1.07G/5.00G [00:03<00:14, 276MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  22%|█    | 1.10G/5.00G [00:03<00:14, 276MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  23%|█▏   | 1.13G/5.00G [00:03<00:13, 277MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  23%|█▏   | 1.16G/5.00G [00:04<00:14, 274MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  24%|█▏   | 1.20G/5.00G [00:04<00:13, 274MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  25%|█▏   | 1.23G/5.00G [00:04<00:13, 275MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  25%|█▎   | 1.26G/5.00G [00:04<00:13, 275MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  26%|█▎   | 1.29G/5.00G [00:04<00:13, 273MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  26%|█▎   | 1.32G/5.00G [00:04<00:13, 272MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  27%|█▎   | 1.35G/5.00G [00:04<00:13, 273MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  28%|█▍   | 1.38G/5.00G [00:04<00:13, 273MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  28%|█▍   | 1.42G/5.00G [00:05<00:13, 272MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  29%|█▍   | 1.45G/5.00G [00:05<00:12, 277MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  30%|█▍   | 1.48G/5.00G [00:05<00:12, 276MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  30%|█▌   | 1.51G/5.00G [00:05<00:12, 275MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  31%|█▌   | 1.54G/5.00G [00:05<00:12, 274MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  31%|█▌   | 1.57G/5.00G [00:05<00:12, 276MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  32%|█▌   | 1.60G/5.00G [00:05<00:12, 274MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  33%|█▋   | 1.64G/5.00G [00:05<00:12, 277MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  33%|█▋   | 1.67G/5.00G [00:05<00:12, 275MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  34%|█▋   | 1.70G/5.00G [00:06<00:11, 278MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  35%|█▋   | 1.73G/5.00G [00:06<00:11, 274MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  35%|█▊   | 1.76G/5.00G [00:06<00:11, 274MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  36%|█▊   | 1.79G/5.00G [00:06<00:11, 276MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  36%|█▊   | 1.82G/5.00G [00:06<00:11, 274MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  37%|█▊   | 1.86G/5.00G [00:06<00:11, 273MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  38%|█▉   | 1.89G/5.00G [00:06<00:11, 273MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  38%|█▉   | 1.92G/5.00G [00:06<00:11, 274MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  39%|█▉   | 1.95G/5.00G [00:06<00:11, 275MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  40%|█▉   | 1.98G/5.00G [00:07<00:11, 272MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  40%|██   | 2.01G/5.00G [00:07<00:10, 272MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  41%|██   | 2.04G/5.00G [00:07<00:10, 271MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  42%|██   | 2.08G/5.00G [00:07<00:10, 269MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  42%|██   | 2.11G/5.00G [00:07<00:10, 269MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  43%|██▏  | 2.14G/5.00G [00:07<00:10, 271MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  43%|██▏  | 2.17G/5.00G [00:07<00:10, 271MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  44%|██▏  | 2.20G/5.00G [00:07<00:10, 270MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  45%|██▏  | 2.23G/5.00G [00:08<00:10, 273MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  45%|██▎  | 2.26G/5.00G [00:08<00:09, 277MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  46%|██▎  | 2.30G/5.00G [00:08<00:09, 279MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  47%|██▎  | 2.33G/5.00G [00:08<00:09, 282MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  47%|██▎  | 2.36G/5.00G [00:08<00:09, 282MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  48%|██▍  | 2.39G/5.00G [00:08<00:09, 282MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  48%|██▍  | 2.42G/5.00G [00:08<00:09, 283MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  49%|██▍  | 2.45G/5.00G [00:08<00:08, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  50%|██▍  | 2.49G/5.00G [00:08<00:08, 281MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  50%|██▌  | 2.52G/5.00G [00:09<00:08, 282MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  51%|██▌  | 2.55G/5.00G [00:09<00:08, 283MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  52%|██▌  | 2.58G/5.00G [00:09<00:08, 283MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  52%|██▌  | 2.61G/5.00G [00:09<00:08, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  53%|██▋  | 2.64G/5.00G [00:09<00:08, 286MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  53%|██▋  | 2.67G/5.00G [00:09<00:08, 286MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  54%|██▋  | 2.71G/5.00G [00:09<00:08, 285MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  55%|██▋  | 2.74G/5.00G [00:09<00:07, 286MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  55%|██▊  | 2.77G/5.00G [00:09<00:07, 287MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  56%|██▊  | 2.80G/5.00G [00:10<00:07, 286MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  57%|██▊  | 2.83G/5.00G [00:10<00:07, 286MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  57%|██▊  | 2.86G/5.00G [00:10<00:07, 287MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  58%|██▉  | 2.89G/5.00G [00:10<00:07, 288MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  59%|██▉  | 2.93G/5.00G [00:10<00:07, 292MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  59%|██▉  | 2.96G/5.00G [00:10<00:06, 293MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  60%|██▉  | 2.99G/5.00G [00:10<00:06, 293MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  60%|███  | 3.02G/5.00G [00:10<00:06, 291MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  61%|███  | 3.05G/5.00G [00:10<00:06, 288MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  62%|███  | 3.08G/5.00G [00:10<00:06, 290MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  62%|███  | 3.11G/5.00G [00:11<00:06, 292MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  63%|███▏ | 3.15G/5.00G [00:11<00:06, 292MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  64%|███▏ | 3.18G/5.00G [00:11<00:06, 266MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  64%|███▏ | 3.21G/5.00G [00:11<00:06, 268MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  65%|███▏ | 3.24G/5.00G [00:11<00:06, 277MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  65%|███▎ | 3.27G/5.00G [00:11<00:06, 283MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  66%|███▎ | 3.30G/5.00G [00:11<00:05, 286MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  67%|███▎ | 3.33G/5.00G [00:11<00:05, 289MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  67%|███▎ | 3.37G/5.00G [00:11<00:05, 290MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  68%|███▍ | 3.40G/5.00G [00:12<00:05, 294MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  69%|███▍ | 3.43G/5.00G [00:12<00:05, 295MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  69%|███▍ | 3.46G/5.00G [00:12<00:05, 294MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  70%|███▍ | 3.49G/5.00G [00:12<00:05, 294MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  70%|███▌ | 3.52G/5.00G [00:12<00:06, 242MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  71%|███▌ | 3.55G/5.00G [00:12<00:08, 170MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  72%|███▌ | 3.59G/5.00G [00:13<00:10, 131MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  72%|███▌ | 3.61G/5.00G [00:13<00:11, 124MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  73%|███▋ | 3.63G/5.00G [00:13<00:11, 119MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  73%|███▋ | 3.65G/5.00G [00:13<00:11, 115MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  73%|███▋ | 3.67G/5.00G [00:14<00:11, 116MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  74%|███▋ | 3.69G/5.00G [00:14<00:11, 115MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  74%|███▋ | 3.71G/5.00G [00:14<00:10, 119MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  75%|███▋ | 3.73G/5.00G [00:14<00:10, 121MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  75%|███▊ | 3.75G/5.00G [00:14<00:09, 127MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  76%|███▊ | 3.77G/5.00G [00:14<00:09, 128MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  76%|███▊ | 3.80G/5.00G [00:14<00:08, 139MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  76%|███▊ | 3.82G/5.00G [00:15<00:10, 109MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  77%|███▊ | 3.85G/5.00G [00:15<00:08, 143MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  78%|███▉ | 3.88G/5.00G [00:15<00:06, 173MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  78%|███▉ | 3.91G/5.00G [00:15<00:05, 199MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  79%|███▉ | 3.94G/5.00G [00:15<00:04, 220MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  79%|███▉ | 3.97G/5.00G [00:15<00:04, 237MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  80%|████ | 4.01G/5.00G [00:15<00:03, 250MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  81%|████ | 4.04G/5.00G [00:16<00:03, 260MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  81%|████ | 4.07G/5.00G [00:16<00:03, 266MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  82%|████ | 4.10G/5.00G [00:16<00:03, 273MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  83%|████▏| 4.13G/5.00G [00:16<00:03, 276MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  83%|████▏| 4.16G/5.00G [00:16<00:02, 279MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  84%|████▏| 4.19G/5.00G [00:16<00:02, 283MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  85%|████▏| 4.23G/5.00G [00:16<00:02, 277MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  85%|████▎| 4.26G/5.00G [00:16<00:02, 263MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  86%|████▎| 4.29G/5.00G [00:16<00:02, 263MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  86%|████▎| 4.32G/5.00G [00:17<00:02, 262MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  87%|████▎| 4.35G/5.00G [00:17<00:02, 261MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  88%|████▍| 4.38G/5.00G [00:17<00:02, 270MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  88%|████▍| 4.41G/5.00G [00:17<00:02, 244MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  89%|████▍| 4.45G/5.00G [00:17<00:02, 203MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  90%|████▍| 4.48G/5.00G [00:17<00:02, 188MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  90%|████▍| 4.50G/5.00G [00:18<00:02, 184MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  91%|████▌| 4.53G/5.00G [00:18<00:02, 206MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  91%|████▌| 4.56G/5.00G [00:18<00:02, 219MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  92%|████▌| 4.59G/5.00G [00:18<00:01, 227MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  92%|████▌| 4.62G/5.00G [00:18<00:01, 231MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  93%|████▋| 4.66G/5.00G [00:18<00:01, 241MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  94%|████▋| 4.69G/5.00G [00:18<00:01, 242MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  94%|████▋| 4.72G/5.00G [00:18<00:01, 245MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  95%|████▊| 4.75G/5.00G [00:19<00:00, 251MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  96%|████▊| 4.78G/5.00G [00:19<00:00, 247MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  96%|████▊| 4.81G/5.00G [00:19<00:00, 248MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  97%|████▊| 4.84G/5.00G [00:19<00:00, 251MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  98%|████▉| 4.88G/5.00G [00:19<00:00, 249MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  98%|████▉| 4.91G/5.00G [00:19<00:00, 254MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  99%|████▉| 4.94G/5.00G [00:19<00:00, 253MB/s]\u001b[A\nmodel-00002-of-00004.safetensors:  99%|████▉| 4.97G/5.00G [00:19<00:00, 251MB/s]\u001b[A\nmodel-00002-of-00004.safetensors: 100%|█████| 5.00G/5.00G [00:20<00:00, 250MB/s]\u001b[A\nDownloading shards:  50%|████████████▌            | 2/4 [00:38<00:38, 19.23s/it]\nmodel-00003-of-00004.safetensors:   0%|             | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\nmodel-00003-of-00004.safetensors:   1%|     | 31.5M/4.92G [00:00<00:15, 306MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   1%|     | 62.9M/4.92G [00:00<00:17, 283MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   2%|     | 94.4M/4.92G [00:00<00:17, 279MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   3%|▏     | 126M/4.92G [00:00<00:17, 276MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   3%|▏     | 157M/4.92G [00:00<00:17, 274MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   4%|▏     | 189M/4.92G [00:00<00:17, 272MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   4%|▎     | 220M/4.92G [00:00<00:17, 272MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   5%|▎     | 252M/4.92G [00:00<00:17, 272MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   6%|▎     | 283M/4.92G [00:01<00:17, 271MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   6%|▍     | 315M/4.92G [00:01<00:16, 272MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   7%|▍     | 346M/4.92G [00:01<00:16, 270MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   8%|▍     | 377M/4.92G [00:01<00:17, 266MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   8%|▍     | 409M/4.92G [00:01<00:17, 264MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:   9%|▌     | 440M/4.92G [00:01<00:16, 268MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  10%|▌     | 472M/4.92G [00:01<00:16, 266MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  10%|▌     | 503M/4.92G [00:01<00:16, 263MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  11%|▋     | 535M/4.92G [00:01<00:16, 267MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  12%|▋     | 566M/4.92G [00:02<00:16, 269MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  12%|▋     | 598M/4.92G [00:02<00:16, 269MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  13%|▊     | 629M/4.92G [00:02<00:15, 273MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  13%|▊     | 661M/4.92G [00:02<00:15, 278MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  14%|▊     | 692M/4.92G [00:02<00:15, 278MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  15%|▉     | 724M/4.92G [00:02<00:15, 279MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  15%|▉     | 755M/4.92G [00:02<00:14, 280MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  16%|▉     | 786M/4.92G [00:02<00:14, 281MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  17%|▉     | 818M/4.92G [00:02<00:14, 279MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  17%|█     | 849M/4.92G [00:03<00:14, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  18%|█     | 881M/4.92G [00:03<00:14, 285MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  19%|█     | 912M/4.92G [00:03<00:13, 287MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  19%|█▏    | 944M/4.92G [00:03<00:13, 285MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  20%|█▏    | 975M/4.92G [00:03<00:13, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  20%|█    | 1.01G/4.92G [00:03<00:13, 280MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  21%|█    | 1.04G/4.92G [00:03<00:14, 277MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  22%|█    | 1.07G/4.92G [00:03<00:13, 277MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  22%|█    | 1.10G/4.92G [00:03<00:13, 280MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  23%|█▏   | 1.13G/4.92G [00:04<00:13, 281MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  24%|█▏   | 1.16G/4.92G [00:04<00:13, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  24%|█▏   | 1.20G/4.92G [00:04<00:13, 281MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  25%|█▏   | 1.23G/4.92G [00:04<00:13, 281MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  26%|█▎   | 1.26G/4.92G [00:04<00:12, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  26%|█▎   | 1.29G/4.92G [00:04<00:12, 281MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  27%|█▎   | 1.32G/4.92G [00:04<00:12, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  28%|█▍   | 1.35G/4.92G [00:04<00:12, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  28%|█▍   | 1.38G/4.92G [00:05<00:12, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  29%|█▍   | 1.42G/4.92G [00:05<00:12, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  29%|█▍   | 1.45G/4.92G [00:05<00:12, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  30%|█▌   | 1.48G/4.92G [00:05<00:12, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  31%|█▌   | 1.51G/4.92G [00:05<00:12, 283MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  31%|█▌   | 1.54G/4.92G [00:05<00:11, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  32%|█▌   | 1.57G/4.92G [00:05<00:11, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  33%|█▋   | 1.60G/4.92G [00:05<00:12, 273MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  33%|█▋   | 1.64G/4.92G [00:06<00:15, 206MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  34%|█▋   | 1.67G/4.92G [00:06<00:24, 133MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  35%|█▋   | 1.70G/4.92G [00:06<00:20, 157MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  35%|█▊   | 1.73G/4.92G [00:06<00:18, 175MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  36%|█▊   | 1.76G/4.92G [00:06<00:18, 173MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  36%|█▊   | 1.79G/4.92G [00:07<00:16, 190MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  37%|█▊   | 1.82G/4.92G [00:07<00:15, 205MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  38%|█▉   | 1.86G/4.92G [00:07<00:14, 210MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  38%|█▉   | 1.89G/4.92G [00:07<00:13, 225MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  39%|█▉   | 1.92G/4.92G [00:07<00:12, 237MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  40%|█▉   | 1.95G/4.92G [00:07<00:12, 230MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  40%|█▌  | 1.98G/4.92G [00:09<00:48, 60.6MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  41%|█▋  | 2.00G/4.92G [00:09<00:40, 71.9MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  41%|█▋  | 2.03G/4.92G [00:09<00:30, 93.7MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  42%|██   | 2.07G/4.92G [00:09<00:24, 118MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  43%|██▏  | 2.10G/4.92G [00:09<00:19, 143MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  43%|██▏  | 2.13G/4.92G [00:09<00:16, 167MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  44%|██▏  | 2.16G/4.92G [00:09<00:14, 190MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  45%|██▏  | 2.19G/4.92G [00:09<00:12, 211MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  45%|██▎  | 2.22G/4.92G [00:09<00:11, 227MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  46%|██▎  | 2.25G/4.92G [00:10<00:11, 235MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  46%|██▎  | 2.29G/4.92G [00:10<00:10, 249MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  47%|██▎  | 2.32G/4.92G [00:10<00:10, 257MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  48%|██▍  | 2.35G/4.92G [00:10<00:09, 260MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  48%|██▍  | 2.38G/4.92G [00:10<00:09, 266MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  49%|██▍  | 2.41G/4.92G [00:10<00:09, 269MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  50%|██▍  | 2.44G/4.92G [00:10<00:09, 274MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  50%|██▌  | 2.47G/4.92G [00:10<00:08, 278MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  51%|██▌  | 2.51G/4.92G [00:11<00:08, 280MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  52%|██▌  | 2.54G/4.92G [00:11<00:08, 280MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  52%|██▌  | 2.57G/4.92G [00:11<00:08, 276MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  53%|██▋  | 2.60G/4.92G [00:11<00:08, 274MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  54%|██▏ | 2.63G/4.92G [00:13<00:47, 48.4MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  54%|██▏ | 2.66G/4.92G [00:13<00:35, 63.3MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  55%|██▏ | 2.68G/4.92G [00:13<00:30, 74.3MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  55%|██▏ | 2.72G/4.92G [00:13<00:22, 96.8MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  56%|██▊  | 2.75G/4.92G [00:13<00:18, 120MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  57%|██▊  | 2.78G/4.92G [00:13<00:14, 147MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  57%|██▊  | 2.81G/4.92G [00:13<00:12, 172MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  58%|██▉  | 2.84G/4.92G [00:14<00:10, 195MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  58%|██▉  | 2.87G/4.92G [00:14<00:09, 214MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  59%|██▉  | 2.90G/4.92G [00:14<00:08, 230MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  60%|██▉  | 2.94G/4.92G [00:14<00:08, 244MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  60%|███  | 2.97G/4.92G [00:14<00:07, 253MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  61%|███  | 3.00G/4.92G [00:14<00:07, 262MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  62%|███  | 3.03G/4.92G [00:14<00:07, 268MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  62%|███  | 3.06G/4.92G [00:14<00:06, 274MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  63%|███▏ | 3.09G/4.92G [00:14<00:06, 277MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  64%|███▏ | 3.12G/4.92G [00:15<00:06, 279MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  64%|███▏ | 3.16G/4.92G [00:15<00:06, 272MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  65%|███▏ | 3.19G/4.92G [00:15<00:06, 276MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  65%|███▎ | 3.22G/4.92G [00:15<00:06, 278MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  66%|███▎ | 3.25G/4.92G [00:15<00:05, 279MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  67%|███▎ | 3.28G/4.92G [00:15<00:05, 280MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  67%|███▎ | 3.31G/4.92G [00:15<00:05, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  68%|███▍ | 3.34G/4.92G [00:15<00:05, 282MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  69%|███▍ | 3.38G/4.92G [00:15<00:05, 285MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  69%|███▍ | 3.41G/4.92G [00:16<00:05, 284MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  70%|███▍ | 3.44G/4.92G [00:16<00:05, 284MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  71%|███▌ | 3.47G/4.92G [00:16<00:05, 286MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  71%|██▊ | 3.50G/4.92G [00:17<00:23, 59.5MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  72%|██▊ | 3.52G/4.92G [00:17<00:20, 68.1MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  72%|██▉ | 3.54G/4.92G [00:19<00:36, 37.4MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  73%|██▉ | 3.57G/4.92G [00:19<00:29, 46.1MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  73%|██▉ | 3.60G/4.92G [00:20<00:40, 32.2MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  74%|██▉ | 3.62G/4.92G [00:21<00:32, 40.2MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  74%|██▉ | 3.64G/4.92G [00:22<00:45, 28.1MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  74%|██▉ | 3.66G/4.92G [00:22<00:34, 36.3MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  75%|███ | 3.69G/4.92G [00:24<00:41, 29.4MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  76%|███ | 3.71G/4.92G [00:24<00:32, 37.0MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  76%|███ | 3.74G/4.92G [00:24<00:22, 52.7MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  77%|███ | 3.77G/4.92G [00:24<00:15, 72.1MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  77%|███ | 3.81G/4.92G [00:24<00:11, 94.6MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  78%|███▉ | 3.84G/4.92G [00:24<00:09, 119MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  79%|███▉ | 3.87G/4.92G [00:24<00:07, 142MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  79%|███▉ | 3.90G/4.92G [00:24<00:06, 166MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  80%|███▉ | 3.93G/4.92G [00:25<00:05, 188MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  81%|████ | 3.96G/4.92G [00:25<00:04, 208MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  81%|████ | 4.00G/4.92G [00:25<00:04, 223MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  82%|████ | 4.03G/4.92G [00:25<00:03, 232MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  83%|████▏| 4.06G/4.92G [00:25<00:03, 241MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  83%|████▏| 4.09G/4.92G [00:25<00:03, 251MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  84%|████▏| 4.12G/4.92G [00:25<00:03, 255MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  84%|████▏| 4.15G/4.92G [00:25<00:02, 259MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  85%|████▎| 4.18G/4.92G [00:25<00:02, 262MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  86%|████▎| 4.22G/4.92G [00:26<00:02, 263MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  86%|████▎| 4.25G/4.92G [00:26<00:02, 266MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  87%|████▎| 4.28G/4.92G [00:26<00:02, 269MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  88%|████▍| 4.31G/4.92G [00:26<00:02, 271MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  88%|████▍| 4.34G/4.92G [00:26<00:02, 274MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  89%|████▍| 4.37G/4.92G [00:26<00:02, 268MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  90%|████▍| 4.40G/4.92G [00:26<00:01, 269MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  90%|████▌| 4.44G/4.92G [00:26<00:01, 270MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  91%|████▌| 4.47G/4.92G [00:27<00:01, 271MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  92%|████▌| 4.50G/4.92G [00:27<00:01, 270MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  92%|████▌| 4.53G/4.92G [00:27<00:01, 269MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  93%|████▋| 4.56G/4.92G [00:27<00:01, 269MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  93%|████▋| 4.59G/4.92G [00:27<00:01, 267MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  94%|████▋| 4.62G/4.92G [00:27<00:01, 176MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  95%|████▋| 4.66G/4.92G [00:27<00:01, 200MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  95%|████▊| 4.69G/4.92G [00:28<00:01, 220MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  96%|████▊| 4.72G/4.92G [00:28<00:00, 238MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  97%|████▊| 4.75G/4.92G [00:28<00:00, 249MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  97%|████▊| 4.78G/4.92G [00:28<00:00, 259MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  98%|████▉| 4.81G/4.92G [00:28<00:00, 266MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  99%|████▉| 4.84G/4.92G [00:28<00:00, 273MB/s]\u001b[A\nmodel-00003-of-00004.safetensors:  99%|████▉| 4.88G/4.92G [00:28<00:00, 278MB/s]\u001b[A\nmodel-00003-of-00004.safetensors: 100%|█████| 4.92G/4.92G [00:28<00:00, 170MB/s]\u001b[A\nDownloading shards:  75%|██████████████████▊      | 3/4 [01:07<00:23, 23.67s/it]\nmodel-00004-of-00004.safetensors:   0%|             | 0.00/1.17G [00:00<?, ?B/s]\u001b[A\nmodel-00004-of-00004.safetensors:   3%|▏    | 31.5M/1.17G [00:00<00:03, 309MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:   5%|▎    | 62.9M/1.17G [00:00<00:03, 295MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:   8%|▍    | 94.4M/1.17G [00:00<00:03, 292MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  11%|▋     | 126M/1.17G [00:00<00:03, 290MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  13%|▊     | 157M/1.17G [00:00<00:03, 287MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  16%|▉     | 189M/1.17G [00:00<00:03, 287MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  19%|█▏    | 220M/1.17G [00:00<00:03, 287MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  22%|█▎    | 252M/1.17G [00:00<00:03, 285MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  24%|█▍    | 283M/1.17G [00:00<00:03, 284MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  27%|█▌    | 315M/1.17G [00:01<00:02, 285MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  30%|█▊    | 346M/1.17G [00:01<00:02, 283MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  32%|█▉    | 377M/1.17G [00:01<00:02, 283MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  35%|██    | 409M/1.17G [00:01<00:02, 283MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  38%|██▎   | 440M/1.17G [00:01<00:02, 283MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  40%|██▍   | 472M/1.17G [00:01<00:02, 285MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  43%|██▌   | 503M/1.17G [00:01<00:02, 286MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  46%|██▋   | 535M/1.17G [00:01<00:02, 285MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  48%|██▉   | 566M/1.17G [00:01<00:02, 286MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  51%|███   | 598M/1.17G [00:02<00:01, 286MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  54%|███▏  | 629M/1.17G [00:02<00:01, 286MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  57%|███▍  | 661M/1.17G [00:02<00:01, 286MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  59%|███▌  | 692M/1.17G [00:02<00:01, 286MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  62%|███▋  | 724M/1.17G [00:02<00:01, 285MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  65%|███▉  | 755M/1.17G [00:02<00:01, 284MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  67%|████  | 786M/1.17G [00:02<00:01, 284MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  70%|████▏ | 818M/1.17G [00:02<00:01, 285MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  73%|████▎ | 849M/1.17G [00:02<00:01, 286MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  75%|████▌ | 881M/1.17G [00:03<00:01, 287MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  78%|████▋ | 912M/1.17G [00:03<00:00, 287MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  81%|████▊ | 944M/1.17G [00:03<00:00, 285MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  83%|█████ | 975M/1.17G [00:03<00:00, 287MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  86%|████▎| 1.01G/1.17G [00:03<00:00, 289MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  89%|████▍| 1.04G/1.17G [00:03<00:00, 287MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  92%|████▌| 1.07G/1.17G [00:03<00:00, 289MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  94%|████▋| 1.10G/1.17G [00:03<00:00, 289MB/s]\u001b[A\nmodel-00004-of-00004.safetensors:  97%|████▊| 1.13G/1.17G [00:03<00:00, 292MB/s]\u001b[A\nmodel-00004-of-00004.safetensors: 100%|█████| 1.17G/1.17G [00:04<00:00, 287MB/s]\u001b[A\nDownloading shards: 100%|█████████████████████████| 4/4 [01:11<00:00, 17.82s/it]\nDownloading shards: 100%|█████████████████████████| 4/4 [01:11<00:00, 17.81s/it]\nLoading checkpoint shards: 100%|██████████████████| 4/4 [01:31<00:00, 22.78s/it]\nLoading checkpoint shards: 100%|██████████████████| 4/4 [01:31<00:00, 22.80s/it]\ngeneration_config.json: 100%|███████████████████| 187/187 [00:00<00:00, 932kB/s]\nGenerating train split: 118 examples [00:00, 518.36 examples/s]\nGenerating train split: 11 examples [00:00, 560.42 examples/s]\ntrainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5195983464188562\n{'loss': 2.3077, 'grad_norm': 0.3828125, 'learning_rate': 0.0005, 'epoch': 0.34}\n{'loss': 1.8764, 'grad_norm': 0.796875, 'learning_rate': 0.0005, 'epoch': 0.68} \n 25%|██████████▌                               | 29/116 [12:02<36:23, 25.09s/it]\n  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n 33%|███████████████                              | 2/6 [00:03<00:07,  2.00s/it]\u001b[A\n 50%|██████████████████████▌                      | 3/6 [00:07<00:08,  2.83s/it]\u001b[A\n 67%|██████████████████████████████               | 4/6 [00:11<00:06,  3.27s/it]\u001b[A\n 83%|█████████████████████████████████████▌       | 5/6 [00:15<00:03,  3.52s/it]\u001b[A\n100%|█████████████████████████████████████████████| 6/6 [00:19<00:00,  3.68s/it]\u001b[A\n{'eval_loss': 1.7221022844314575, 'eval_runtime': 24.0972, 'eval_samples_per_second': 0.456, 'eval_steps_per_second': 0.249, 'epoch': 0.98}\n\n 25%|██████████▌                               | 29/116 [12:38<36:23, 25.09s/it]\u001b[A\n                                                                                \u001b[A[rank0]:[2024-05-09 02:20:09,541] torch.distributed.fsdp._debug_utils: [WARNING] FSDP _optim_state_dict() profiling:  defaultdict(<class 'float'>, {'preprocessing': 0.6277966770001058, 'preprocessing_with_comm': 0.014339019000090047, 'state_converting': 0.28181157699987125, <Type.ALL: 'all'>: 1.0056916549999642})\n{'loss': 1.8082, 'grad_norm': 0.291015625, 'learning_rate': 0.0005, 'epoch': 1.02}\n{'loss': 1.5941, 'grad_norm': 0.451171875, 'learning_rate': 0.0005, 'epoch': 1.36}\n{'loss': 1.5342, 'grad_norm': 0.5, 'learning_rate': 0.0005, 'epoch': 1.69}      \n 51%|█████████████████████▎                    | 59/116 [25:24<23:50, 25.09s/it]\n  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n 33%|███████████████                              | 2/6 [00:04<00:08,  2.00s/it]\u001b[A\n 50%|██████████████████████▌                      | 3/6 [00:08<00:08,  2.84s/it]\u001b[A\n 67%|██████████████████████████████               | 4/6 [00:12<00:06,  3.28s/it]\u001b[A\n 83%|█████████████████████████████████████▌       | 5/6 [00:16<00:03,  3.53s/it]\u001b[A\n100%|█████████████████████████████████████████████| 6/6 [00:20<00:00,  3.69s/it]\u001b[A\n{'eval_loss': 1.7808078527450562, 'eval_runtime': 24.1865, 'eval_samples_per_second': 0.455, 'eval_steps_per_second': 0.248, 'epoch': 2.0}\n\n 51%|█████████████████████▎                    | 59/116 [25:48<23:50, 25.09s/it]\u001b[A\n                                                                                \u001b[A[rank0]:[2024-05-09 02:33:16,307] torch.distributed.fsdp._debug_utils: [WARNING] FSDP _optim_state_dict() profiling:  defaultdict(<class 'float'>, {'preprocessing': 0.54561864399966, 'preprocessing_with_comm': 0.00587787099993875, 'state_converting': 0.27322725399972114, <Type.ALL: 'all'>: 0.8475119130002895})\n{'loss': 1.4718, 'grad_norm': 0.56640625, 'learning_rate': 0.0005, 'epoch': 2.03}\n{'loss': 1.0783, 'grad_norm': 0.7109375, 'learning_rate': 0.0005, 'epoch': 2.37}\n{'loss': 1.0969, 'grad_norm': 0.73046875, 'learning_rate': 0.0005, 'epoch': 2.71}\n 76%|███████████████████████████████▊          | 88/116 [38:18<11:43, 25.12s/it]\n  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n 33%|███████████████                              | 2/6 [00:04<00:08,  2.01s/it]\u001b[A\n 50%|██████████████████████▌                      | 3/6 [00:08<00:08,  2.85s/it]\u001b[A\n 67%|██████████████████████████████               | 4/6 [00:12<00:06,  3.28s/it]\u001b[A\n 83%|█████████████████████████████████████▌       | 5/6 [00:16<00:03,  3.54s/it]\u001b[A\n100%|█████████████████████████████████████████████| 6/6 [00:20<00:00,  3.70s/it]\u001b[A\n{'eval_loss': 1.9378939867019653, 'eval_runtime': 24.1908, 'eval_samples_per_second': 0.455, 'eval_steps_per_second': 0.248, 'epoch': 2.98}\n\n 76%|███████████████████████████████▊          | 88/116 [38:54<11:43, 25.12s/it]\u001b[A\n                                                                                \u001b[A[rank0]:[2024-05-09 02:46:21,220] torch.distributed.fsdp._debug_utils: [WARNING] FSDP _optim_state_dict() profiling:  defaultdict(<class 'float'>, {'preprocessing': 0.527861294000104, 'preprocessing_with_comm': 0.005313108999871474, 'state_converting': 0.2813972800004194, <Type.ALL: 'all'>: 0.8381092630002058})\n{'loss': 1.0515, 'grad_norm': 0.6875, 'learning_rate': 0.0005, 'epoch': 3.05}   \n{'loss': 0.6675, 'grad_norm': 0.7890625, 'learning_rate': 0.0005, 'epoch': 3.39}\n{'loss': 0.693, 'grad_norm': 0.8125, 'learning_rate': 0.0005, 'epoch': 3.73}    \n100%|█████████████████████████████████████████| 116/116 [50:45<00:00, 25.00s/it]\n  0%|                                                     | 0/6 [00:00<?, ?it/s]\u001b[A\n 33%|███████████████                              | 2/6 [00:04<00:08,  2.00s/it]\u001b[A\n 50%|██████████████████████▌                      | 3/6 [00:07<00:08,  2.83s/it]\u001b[A\n 67%|██████████████████████████████               | 4/6 [00:11<00:06,  3.27s/it]\u001b[A\n 83%|█████████████████████████████████████▌       | 5/6 [00:16<00:03,  3.52s/it]\u001b[A\n100%|█████████████████████████████████████████████| 6/6 [00:20<00:00,  3.68s/it]\u001b[A\n{'eval_loss': 2.1637916564941406, 'eval_runtime': 24.0996, 'eval_samples_per_second': 0.456, 'eval_steps_per_second': 0.249, 'epoch': 3.93}\n\n100%|█████████████████████████████████████████| 116/116 [51:09<00:00, 25.00s/it]\u001b[A\n                                                                                \u001b[A[rank0]:[2024-05-09 02:58:35,444] torch.distributed.fsdp._debug_utils: [WARNING] FSDP _optim_state_dict() profiling:  defaultdict(<class 'float'>, {'preprocessing': 0.49804681800014805, 'preprocessing_with_comm': 0.005591428999650816, 'state_converting': 0.2724948739996762, <Type.ALL: 'all'>: 0.7995096659997216})\n{'train_runtime': 3089.7545, 'train_samples_per_second': 0.153, 'train_steps_per_second': 0.038, 'train_loss': 1.3449032964377567, 'epoch': 3.93}\n100%|█████████████████████████████████████████| 116/116 [51:29<00:00, 26.63s/it]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Inference","metadata":{}},{"cell_type":"code","source":"import torch\nfrom peft import AutoPeftModelForCausalLM\nfrom transformers import AutoTokenizer\n \npeft_model_id = \"/home/jupyter/llama-3-8b-FinGPT\"\n \n# Load Model with PEFT adapter\nmodel = AutoPeftModelForCausalLM.from_pretrained(\n  peft_model_id,\n  torch_dtype=torch.float16,\n  quantization_config= {\"load_in_4bit\": True},\n  device_map=\"auto\"\n)\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:02:26.375628Z","iopub.execute_input":"2024-05-09T03:02:26.375957Z","iopub.status.idle":"2024-05-09T03:03:14.654625Z","shell.execute_reply.started":"2024-05-09T03:02:26.375931Z","shell.execute_reply":"2024-05-09T03:03:14.653659Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc2285f3ad7c4475ac41c7c0d6688bd2"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom random import randint\n \n\n# Load our test dataset\neval_dataset = load_dataset(\"json\", data_files=\"test_dataset.json\", split=\"train\")\nrand_idx = 1\nmessages = eval_dataset[rand_idx][\"messages\"][:2]\n \n# Test on sample\ninput_ids = tokenizer.apply_chat_template(messages,add_generation_prompt=True,return_tensors=\"pt\").to(model.device)\noutputs = model.generate(\n    input_ids,\n    max_new_tokens=256,\n    eos_token_id= tokenizer.eos_token_id,\n    do_sample=True,\n    temperature=0.6,\n    top_p=0.9,\n)\nresponse = outputs[0][input_ids.shape[-1]:]\n\nprint(f\"**Query:**\\n{eval_dataset[rand_idx]['messages'][1]['content']}\\n\")\nprint(f\"**Original Answer:**\\n{eval_dataset[rand_idx]['messages'][2]['content']}\\n\")\nprint(f\"**Generated Answer:**\\n{tokenizer.decode(response,skip_special_tokens=True)}\")\n\n# **Query:**\n# How long was the Revolutionary War?\n# **Original Answer:**\n# The American Revolutionary War lasted just over seven years. The war started on April 19, 1775, and ended on September 3, 1783.\n# **Generated Answer:**\n# The Revolutionary War, also known as the American Revolution, was an 18th-century war fought between the Kingdom of Great Britain and the Thirteen Colonies. The war lasted from 1775 to 1783.","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:05:32.381295Z","iopub.execute_input":"2024-05-09T03:05:32.382332Z","iopub.status.idle":"2024-05-09T03:05:35.048442Z","shell.execute_reply.started":"2024-05-09T03:05:32.382287Z","shell.execute_reply":"2024-05-09T03:05:35.047480Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\nSetting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"**Query:**\nCompany news during this period are listed below:\n\nPositive Headlines:\n\n\nNegative Headlines:\n\n\n\n\n**Original Answer:**\nincreased in 1.84%\n\n**Generated Answer:**\n7.69% increase in stock price or flat.\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Save the model","metadata":{}},{"cell_type":"markdown","source":"##### Zip the lora file\nDownload manually from the output section in the sidebar","metadata":{}},{"cell_type":"code","source":"!ls\n!zip -0 -r llama-3-8b-FinGPT.zip /home/jupyter/llama-3-8b-FinGPT","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:47.672454Z","iopub.execute_input":"2024-05-09T02:59:47.673072Z","iopub.status.idle":"2024-05-09T02:59:55.299314Z","shell.execute_reply.started":"2024-05-09T02:59:47.673030Z","shell.execute_reply":"2024-05-09T02:59:55.298125Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"llama_3_8b_fsdp_qlora.yaml  test_dataset.json\nrun_fsdp_qlora.py\t    train_dataset.json\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"  adding: home/jupyter/llama-3-8b-FinGPT/ (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/special_tokens_map.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/ (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/trainer_state.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/rng_state_0.pth (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/special_tokens_map.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/rng_state_1.pth (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/training_args.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/tokenizer.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/adapter_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/tokenizer_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/scheduler.pt (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/README.md (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/adapter_model.safetensors (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/optimizer.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-29/pytorch_model_fsdp.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/training_args.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/ (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/trainer_state.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/rng_state_0.pth (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/special_tokens_map.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/rng_state_1.pth (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/training_args.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/tokenizer.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/adapter_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/tokenizer_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/scheduler.pt (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/README.md (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/adapter_model.safetensors (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/optimizer.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-116/pytorch_model_fsdp.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/ (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/trainer_state.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/rng_state_0.pth (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/special_tokens_map.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/rng_state_1.pth (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/training_args.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/tokenizer.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/adapter_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/tokenizer_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/scheduler.pt (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/README.md (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/adapter_model.safetensors (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/optimizer.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-88/pytorch_model_fsdp.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/tokenizer.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/adapter_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/tokenizer_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/README.md (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/ (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/trainer_state.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/rng_state_0.pth (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/special_tokens_map.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/rng_state_1.pth (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/training_args.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/tokenizer.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/adapter_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/tokenizer_config.json (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/scheduler.pt (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/README.md (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/adapter_model.safetensors (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/optimizer.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/checkpoint-59/pytorch_model_fsdp.bin (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/adapter_model.safetensors (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/runs/ (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/runs/May09_02-04-13_102a72b38f63/ (stored 0%)\n  adding: home/jupyter/llama-3-8b-FinGPT/runs/May09_02-04-13_102a72b38f63/events.out.tfevents.1715220426.102a72b38f63.154.0 (stored 0%)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"##### Merge PEFT and base model","metadata":{}},{"cell_type":"code","source":"!ls /home/jupyter","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:55.300849Z","iopub.execute_input":"2024-05-09T02:59:55.301166Z","iopub.status.idle":"2024-05-09T02:59:56.305475Z","shell.execute_reply.started":"2024-05-09T02:59:55.301136Z","shell.execute_reply":"2024-05-09T02:59:56.304352Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"llama-3-8b-FinGPT\n","output_type":"stream"}]},{"cell_type":"code","source":"# #### COMMENT IN TO MERGE PEFT AND BASE MODEL ####\nfrom peft import AutoPeftModelForCausalLM\nimport torch\n \n# Load PEFT model on CPU\nmodel = AutoPeftModelForCausalLM.from_pretrained(\n    \"/home/jupyter/llama-3-8b-FinGPT\",\n    torch_dtype=torch.float16,\n    low_cpu_mem_usage=True,\n)\n# Merge LoRA and base model and save\nmerged_model = model.merge_and_unload()\n\n# Save locally\n# merged_model.save_pretrained(\"/home/jupyter/llama-3-8b-FinGPT-Merged\",safe_serialization=True, max_shard_size=\"2GB\")\n# !zip -0 -r llama-3-8b-FinGPT-Merged.zip /home/jupyter/llama-3-8b-FinGPT-Merged\n\n# # Publish to Huggingface\nmerged_model.push_to_hub(\"my-awesome-model\", safe_serialization=True, max_shard_size=\"2GB\")\npeft_model_id = \"/home/jupyter/llama-3-8b-FinGPT\"","metadata":{"execution":{"iopub.status.busy":"2024-05-09T02:59:56.310142Z","iopub.execute_input":"2024-05-09T02:59:56.310474Z","iopub.status.idle":"2024-05-09T03:00:23.385617Z","shell.execute_reply.started":"2024-05-09T02:59:56.310444Z","shell.execute_reply":"2024-05-09T03:00:23.382705Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22d4ea45f47e4dce8202ea02adff59e3"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoPeftModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/jupyter/llama-3-8b-FinGPT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m      9\u001b[0m     low_cpu_mem_usage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Merge LoRA and base model and save\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m merged_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_and_unload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Save locally\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# merged_model.save_pretrained(\"/home/jupyter/llama-3-8b-FinGPT-Merged\",safe_serialization=True, max_shard_size=\"2GB\")\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# !zip -0 -r llama-3-8b-FinGPT-Merged.zip /home/jupyter/llama-3-8b-FinGPT-Merged\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# # Publish to Huggingface\u001b[39;00m\n\u001b[1;32m     19\u001b[0m merged_model\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy-awesome-model\u001b[39m\u001b[38;5;124m\"\u001b[39m, safe_serialization\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_shard_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2GB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/model.py:784\u001b[0m, in \u001b[0;36mLoraModel.merge_and_unload\u001b[0;34m(self, progressbar, safe_merge, adapter_names)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge_and_unload\u001b[39m(\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28mself\u001b[39m, progressbar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, safe_merge: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, adapter_names: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    758\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m    759\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    This method merges the LoRa layers into the base model. This is needed if someone wants to use the base model\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m    as a standalone model.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unload_and_optionally_merge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogressbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_merge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_merge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_names\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/model.py:438\u001b[0m, in \u001b[0;36mLoraModel._unload_and_optionally_merge\u001b[0;34m(self, merge, progressbar, safe_merge, adapter_names)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m merge:\n\u001b[0;32m--> 438\u001b[0m         \u001b[43mtarget\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43msafe_merge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_merge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replace_module(parent, target_name, target\u001b[38;5;241m.\u001b[39mget_base_layer(), target)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(target, ModulesToSaveWrapper):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;66;03m# save any additional trainable modules part of `modules_to_save`\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/layer.py:413\u001b[0m, in \u001b[0;36mLinear.merge\u001b[0;34m(self, safe_merge, adapter_names)\u001b[0m\n\u001b[1;32m    411\u001b[0m     base_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m orig_weights\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 413\u001b[0m     delta_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_delta_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactive_adapter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dora[active_adapter]:\n\u001b[1;32m    415\u001b[0m         base_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m base_layer\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m+\u001b[39m delta_weight\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/lora/layer.py:473\u001b[0m, in \u001b[0;36mLinear.get_delta_weight\u001b[0;34m(self, adapter)\u001b[0m\n\u001b[1;32m    470\u001b[0m     weight_A \u001b[38;5;241m=\u001b[39m weight_A\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    471\u001b[0m     weight_B \u001b[38;5;241m=\u001b[39m weight_B\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m--> 473\u001b[0m output_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_B\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfan_in_fan_out\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaling[adapter]\n\u001b[1;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cast_to_fp32:\n\u001b[1;32m    476\u001b[0m     output_tensor \u001b[38;5;241m=\u001b[39m output_tensor\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mdtype)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:421\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(weight, fan_in_fan_out)\u001b[0m\n\u001b[1;32m    417\u001b[0m     auto_wrap_policy \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(_or_policy, policies\u001b[38;5;241m=\u001b[39m[lambda_policy, transformer_wrap_policy])\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auto_wrap_policy\n\u001b[0;32m--> 421\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranspose\u001b[39m(weight, fan_in_fan_out):\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fan_in_fan_out:\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m weight\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from peft import AutoPeftModelForCausalLM\nfrom transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(peft_model_id)\ntokenizer.push_to_hub(\"my-awesome-model\")","metadata":{"execution":{"iopub.status.busy":"2024-05-09T03:00:23.386505Z","iopub.status.idle":"2024-05-09T03:00:23.386873Z","shell.execute_reply.started":"2024-05-09T03:00:23.386691Z","shell.execute_reply":"2024-05-09T03:00:23.386706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Useful sources\n- https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms\n- https://www.philschmid.de/fsdp-qlora-llama3\n\n- https://www.philschmid.de/fsdp-qlora-llama3#3-fine-tune-the-llm-with-pytorch-fsdp-q-lora-and-sdpa\n- https://www.philschmid.de/fine-tune-llms-in-2024-with-trl#3-create-and-prepare-the-dataset","metadata":{}}]}